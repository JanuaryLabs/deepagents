# Standalone Context Estimation API Spec

## Overview

Add a standalone `estimateContext()` function to `@deepagents/context` that estimates token counts and costs for fragments **before** calling `resolve()` or `save()`, without requiring a `ContextEngine` instance.

## API Signature

```typescript
export async function estimateContext(
  modelId: Models,
  renderer: ContextRenderer,
  ...fragments: ContextFragment[]
): Promise<ContextEstimateResult>
```

## Return Type

```typescript
interface ContextEstimateResult {
  // Total estimate for all fragments combined
  total: {
    tokens: number;
    cost: number;  // Input cost only
  };

  // Per-fragment breakdown (aggregated by fragment.name)
  breakdown: {
    [fragmentName: string]: {
      tokens: number;
      cost: number;
    };
  };

  // Context limit information
  limits: {
    contextLimit: number;      // Model's max context window
    remainingTokens: number;   // contextLimit - total.tokens
    exceedsContext: boolean;   // true if total.tokens > contextLimit
  };

  // Function to calculate output cost from response
  outputCost: (tokenCount: number) => { cost: number };
}
```

## Design Decisions

### 1. Pure Function Export
- Exported from main package: `import { estimateContext } from '@deepagents/context'`
- Uses shared model registry cache internally (same as existing ContextEngine.estimate)

### 2. Input Type
- Only accepts `ContextFragment[]` (via spread)
- User renders fragments with chosen renderer before estimation
- Single signature - no string overload (wrap strings in `fragment()` if needed)

### 3. Renderer Instance
- User passes renderer **instance** (not class)
- Allows full control over renderer configuration
- Renderer options may affect token count

### 4. Async Always
- Always returns `Promise<ContextEstimateResult>`
- Internally fetches/caches model metadata from models.dev API
- Keeps API consistent and simple

### 5. Breakdown Aggregation
- Same-named fragments are aggregated: `{ hint: { tokens: 250 } }` (sum of all hints)
- Nested fragments show parent totals (includes all children)
- Just totals - no fragment count or sub-breakdown

### 6. Cost Calculation
- `total.cost` = input cost only (what you're about to send)
- `outputCost(tokenCount)` function for calculating response cost after API call
- Accepts token count directly (since most APIs return usage stats)

### 7. Limit Checks
- Includes context window check against model limits
- Returns `remainingTokens` for budget planning
- Returns `exceedsContext: boolean` for quick validation

### 8. Error Handling
- Throws error if model ID not found in registry
- Uses existing error handling patterns from ModelsRegistry

### 9. Separate from ContextEngine
- Keep `ContextEngine.estimate()` as separate implementation
- No refactoring of existing code
- Both can coexist independently

### 10. Caching
- Uses existing caching strategy from ModelsRegistry
- Models bundled at build time, fetched updates at runtime

## Usage Examples

### Basic Usage
```typescript
import { estimateContext, XmlRenderer, role, hint, user } from '@deepagents/context';

const result = await estimateContext(
  'gpt-4',
  new XmlRenderer(),
  role('You are a helpful assistant'),
  hint('Be concise'),
  user('Hello, how are you?')
);

console.log(result.total.tokens);          // 45
console.log(result.total.cost);            // 0.00135
console.log(result.limits.exceedsContext); // false
console.log(result.breakdown);             // { role: {...}, hint: {...}, user: {...} }
```

### Calculate Output Cost After Response
```typescript
const result = await estimateContext('gpt-4', new XmlRenderer(), ...fragments);

// After API call, when you have the response
const usage = response.usage; // { completion_tokens: 150 }
const outputCost = result.outputCost(usage.completion_tokens);

console.log(`Total cost: ${result.total.cost + outputCost.cost}`);
```

### Pre-flight Check
```typescript
const result = await estimateContext('gpt-4', new ToonRenderer(), ...fragments);

if (result.limits.exceedsContext) {
  throw new Error(`Context too large by ${-result.limits.remainingTokens} tokens`);
}

if (result.limits.remainingTokens < 1000) {
  console.warn('Low on context budget, consider summarizing');
}
```

### Compare Renderers
```typescript
const xmlEstimate = await estimateContext('gpt-4', new XmlRenderer(), ...fragments);
const toonEstimate = await estimateContext('gpt-4', new ToonRenderer(), ...fragments);

console.log(`XML: ${xmlEstimate.total.tokens} tokens`);
console.log(`TOON: ${toonEstimate.total.tokens} tokens`);
console.log(`Savings: ${xmlEstimate.total.tokens - toonEstimate.total.tokens} tokens`);
```

## Implementation Notes

1. Render each fragment individually to get per-fragment token counts
2. Aggregate by `fragment.name` for breakdown
3. Sum all for total
4. Use existing `gpt-tokenizer` for token counting
5. Use existing `ModelsRegistry` for model metadata and pricing
6. Return closure for `outputCost` that captures output pricing from model metadata
